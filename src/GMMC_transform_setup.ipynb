{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective of this file is to provide the transform_GMMC function  \n",
    "\n",
    "# def transform_GMMC(data: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Transform the dataset into the desired structure and filters.\"\"\"\n",
    "#     logging.info(f\"Transforming data, initial size: {data.shape}\")\n",
    "#     # Example transformation: adding more realistic transformations\n",
    "#     # This is a placeholder. Actual transformations depend on the specific needs.\n",
    "#     df = data\n",
    "#     logging.info(f\"Transformed data size: {df.shape}\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl import extract_csv\n",
    "import pandas as pd\n",
    "\n",
    "path='data_storage/GMMC/raw_data/GMMC-2020-M.csv'\n",
    "total_path='../'+path\n",
    "df= extract_csv(total_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)\n",
    "# How to show ful length of the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(3)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "df.rename(columns={\n",
    "    '@id': 'ID',\n",
    "    'sample.samplingPoint': 'Sampling Point',\n",
    "    'sample.samplingPoint.notation': 'Sampling Point Notation',\n",
    "    'sample.samplingPoint.label': 'Sampling Point Label',\n",
    "    'sample.sampleDateTime': 'Sample Date and Time',\n",
    "    'determinand.label': 'Determinand Label',\n",
    "    'determinand.definition': 'Determinand Definition',\n",
    "    'determinand.notation': 'Determinand Notation',\n",
    "    'resultQualifier.notation': 'Result Qualifier Notation',\n",
    "    'result': 'Result',\n",
    "    'codedResultInterpretation.interpretation': 'Result Interpretation',\n",
    "    'determinand.unit.label': 'Unit',\n",
    "    'sample.sampledMaterialType.label': 'Sample Material Type',\n",
    "    'sample.isComplianceSample': 'Is Compliance Sample',\n",
    "    'sample.purpose.label': 'Sample Purpose',\n",
    "    'sample.samplingPoint.easting': 'Easting',\n",
    "    'sample.samplingPoint.northing': 'Northing'\n",
    "}, inplace=True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Result Interpretation column\n",
    "df.drop(columns=['Result Interpretation','Result Qualifier Notation'], inplace=True)\n",
    "# determine the number of missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ID', 'Sampling Point', 'Sampling Point Notation', 'Sampling Point Label', 'Sample Date and Time', 'Determinand Label', 'Determinand Definition', 'Determinand Notation', 'Result Qualifier Notation', 'Result', 'Result Interpretation', 'Unit', 'Sample Material Type', 'Is Compliance Sample', 'Sample Purpose', 'Easting', 'Northing']\n",
    "\n",
    "# get numerical columns\n",
    "numerical_columns =['Determinand Notation', 'Result', 'Easting',\n",
    "       'Northing']\n",
    "\n",
    "# Get text columns those that are not numerical\n",
    "text_columns = [col for col in features if col not in numerical_columns]\n",
    "text_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'Sampling Point' is the same as 'Sampling Point Notation' e.g. http://environment.data.gov.uk/water-quality/id/sampling-point/NW-1086\n",
    "and NW-1086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Sampling Point'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[text_columns].head(3)\n",
    "df[['ID']].head(3)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In id we have http://environment.data.gov.uk/water-quality/data/measurement/NW-5286182-0135\n",
    "# We need to extract the last part of the string\n",
    "df['ID'] = df['ID'].str.split('/').str[-1]\n",
    "df[['ID']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_columns].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sample Date and Time']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the Sample Date and Time to datetime\n",
    "df['Sample Date and Time'] = pd.to_datetime(df['Sample Date and Time'])\n",
    "df[['Sample Date and Time']].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from etl import extract_csv\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def transform_GMMC(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform the dataset into the desired structure and filters.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Input dataframe to be transformed.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Transformed dataframe.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Transforming data, initial size: {data.shape}\")\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    data.rename(columns={\n",
    "        '@id': 'ID',\n",
    "        'sample.samplingPoint': 'Sampling Point',\n",
    "        'sample.samplingPoint.notation': 'Sampling Point Notation',\n",
    "        'sample.samplingPoint.label': 'Sampling Point Label',\n",
    "        'sample.sampleDateTime': 'Sample Date and Time',\n",
    "        'determinand.label': 'Determinand Label',\n",
    "        'determinand.definition': 'Determinand Definition',\n",
    "        'determinand.notation': 'Determinand Notation',\n",
    "        'resultQualifier.notation': 'Result Qualifier Notation',\n",
    "        'result': 'Result',\n",
    "        'codedResultInterpretation.interpretation': 'Result Interpretation',\n",
    "        'determinand.unit.label': 'Unit',\n",
    "        'sample.sampledMaterialType.label': 'Sample Material Type',\n",
    "        'sample.isComplianceSample': 'Is Compliance Sample',\n",
    "        'sample.purpose.label': 'Sample Purpose',\n",
    "        'sample.samplingPoint.easting': 'Easting',\n",
    "        'sample.samplingPoint.northing': 'Northing'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    data.drop(columns=['Result Interpretation', 'Result Qualifier Notation', 'Sampling Point'], inplace=True)\n",
    "    \n",
    "    # Extract the last part of the string from the ID column\n",
    "    data['ID'] = data['ID'].str.split('/').str[-1]\n",
    "    \n",
    "    # Convert the Sample Date and Time to datetime\n",
    "    data['Sample Date and Time'] = pd.to_datetime(data['Sample Date and Time'])\n",
    "    \n",
    "    logging.info(f\"Transformed data size: {data.shape}\")\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    # Path to the data file\n",
    "    path = 'data_storage/GMMC/raw_data/GMMC-2020-M.csv'\n",
    "    total_path = '../' + path\n",
    "    \n",
    "    try:\n",
    "        # Extract the CSV data\n",
    "        df = extract_csv(total_path)\n",
    "        \n",
    "        # Perform the transformation\n",
    "        transformed_df = transform_GMMC(df)\n",
    "        \n",
    "        # Display the first few rows of the transformed dataframe (for debugging purposes)\n",
    "        logging.info(f\"First few rows of transformed data:\\n{transformed_df.head(3)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
